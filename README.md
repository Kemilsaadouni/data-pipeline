# ğŸ“Š Iris Data Pipeline

## ğŸ“„ Description du projet

Ce projet est un pipeline complet de traitement et de modÃ©lisation de donnÃ©es autour du dataset **Iris**.  
L'objectif est de prÃ©dire la **longueur des sÃ©pales** (`sepal length`) Ã  partir de leur **largeur** (`sepal width`), en utilisant un modÃ¨le **RandomForest** et un dÃ©ploiement via une API dockerisÃ©e.

Nous utilisons **Docker**, **Docker Compose**, **PostgreSQL**, **MLflow**, **scikit-learn**, **FastAPI** et **SQLAlchemy** pour concevoir un projet modulaire, rÃ©plicable et traÃ§able.

## âš–ï¸ PrÃ©-requis

- Docker
- Docker Compose

CrÃ©er un fichier `.env` Ã  la racine du projet avec les paramÃ¨tres suivant en dÃ©finissant les vÃ´tres bien sÃ»r:

```env
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_DB=iris
POSTGRES_HOST=db
```

De plus, n'oubliez pas de dÃ©marrer les services **Docker** et notamment **Docker Desktop** avant de commencer l'installation.

## ğŸš€ Installation

Cloner le projet :
```bash
git clone <lien-du-repo>
cd data-pipeline
```

Construire les services :
```bash
docker-compose build --no-cache api
```

DÃ©marrer le pipeline :
```bash
docker-compose up api
```

âš ï¸ Si il y a un problÃ¨me n'hÃ©sitez pas Ã  exÃ©cuter la commande suivante:
```bash
docker-compose down
```
â¡ï¸ ensuite recommencez Ã  partir de l'Ã©tape de construction des services

## ğŸ“† DÃ©marrage et exploration

### API (FastAPI)
- Visitez : [http://localhost:8000](http://localhost:8000) â€” page d'accueil
- Documentation : [http://localhost:8000/docs](http://localhost:8000/docs) (Swagger UI)

Exemple de requÃªte POST dans `/predict` :
```json
{
  "sepal_width": 3.1
}
```

Exemple de rÃ©ponse attendue :
```json
{
  "predicted_sepal_length": 6.261679143079142
}
```

### MLflow UI

Accessible via : [http://localhost:5000](http://localhost:5000)

Permet de visualiser :
- Les expÃ©riences
- Les mÃ©triques (RMSE, etc...)
- Les versions de modÃ¨les

## ğŸ“ AccÃ¨s Ã  la base de donnÃ©es

Connexion la base de donnÃ©es depuis le conteneur Docker `db`:
```bash
docker exec -it db psql -U user -d iris
```

Commandes utiles :
```sql
-- Voir les tables
\dt

-- AperÃ§u des donnÃ©es
SELECT * FROM iris_data LIMIT 5;
```

## ğŸ” Structure du projet

```bash
data-pipeline/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ data/               # Dataset CSV
â”‚   â””â”€â”€ iris.csv
â”‚
â”œâ”€â”€ preprocessing/      # Preprocessing module
â”‚   â””â”€â”€ app.py
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ model/              # EntraÃ®nement du modÃ¨le
â”‚   â””â”€â”€ train.py
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ api/                # API FastAPI
â”‚   â””â”€â”€ main.py
â”‚   â””â”€â”€ Dockerfile
```
## ğŸ¤– FabriquÃ© avec
- Python 3.10
- FastAPI
- scikit-learn
- PostgreSQL
- MLflow
- Docker / Docker Compose
- SQLAlchemy

## ğŸ”„ Pistes d'amÃ©lioration
- Ajouter un Dockerfile personnalisÃ© pour MLflow (stockage distant, tracking avancÃ©)
- Ã‰tendre le modÃ¨le Ã  d'autres features (ex. largeur/longueur des pÃ©tales)
- Meilleure gestion des erreurs dans lâ€™API
- CrÃ©er une interface front (web) pour l'utilisateur final